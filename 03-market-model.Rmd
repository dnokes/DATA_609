# Market Model {#market-model}

We define and use a simple discrete time model to simulate a broad set of market conditions. Each scenario consists of realizations of both price and true range (defined in Chapter \@ref(intro), Equation \@ref(eq:introTrueRange)).

## Model Specification

The following discrete time process is used to generate price realizations for a single instrument:

\begin{equation}
  P_{t}=P_{t-1} \exp \bigg( \mu\Delta t+\sigma_{t}\epsilon_{t} \bigg)
  (\#eq:marketModelPriceProcess)
\end{equation}  
  
where $t=1 \dots T$, $\Delta t = 1/T$, $\epsilon_{t} \sim N(0,1)$, $\sigma_{t}$ is the time-varying volatility, and $\mu$ is the constant drift for the instrument over time period, $T$.

The volatility is a function of the observed true range, $R_{t}$ [@Chou2005-tt]:

\begin{equation}
  \sigma_{t} = \sqrt{\frac{\pi}{8}}R_{t}
  (\#eq:marketModelRangeToVol)
\end{equation}  

Similar to the work of [@Chou2005-tt] and [@Brunetti2007-uu], we extend a model originally designed for the modeling of duration time series to time-varying price range. Following [@Beran2015-kz], the true range at time, $t$, is given by:

\begin{equation}
  R_{t}=v\lambda_{t}\eta_{t}
  (\#eq:marketModelRangeProcess)
\end{equation} 

where $v$ is a scale parameter ($v>0$), $\lambda_{t}$ is the conditional mean of the true range ($\lambda_t>0$) divided by $v$, and $\eta_{t}$ is an independent and identically distributed (i.i.d) log-normal random variable.

After subtracting the unconditional mean, $\log(v)$, the log true range is represented as a zero mean FARIMA($p$,$d$,$q$) process

\begin{equation}
  Z_{t}=\log(R_{t})-\log(v)=\log(\lambda_{t})+e_{t}
(\#eq:marketModelLogRangeProcess)
\end{equation} 

with innovations, $e=\log(\eta_{t})$, given by

\begin{equation}
  (1-B)^{d}\phi(B)Z_{t}=\psi(B)e_{t}
  (\#eq:EFARIMApdq)
\end{equation}

where $d$ is the long memory parameter ($0 < d < 0.5$), $B$ is the back-shift (or lag operator)\footnote{The back-shift operator is used for notational convenience. $B^{m}x_{t}=x_{t-m}$. $B$ notation allows (even infinite) distributed lags to be represented concisely.}, and $\phi(z)=1-\phi_{1}z-\ldots-\phi_{p}z^{p}$ and $\psi(z)=1+\psi_{1}+\ldots+\psi_{q}z^{q}$ are MA- and AR-polynomials with all roots outside the unit circle\footnote{Wold's decomposition - a fundamental theorem in time series analysis - states that every weakly stationary, purely non-deterministic, stochastic process $(x_{t}-\mu)$ can be written as a linear combination (or linear filter) or a sequence of uncorrelated random variables. See [@Mills1999-bo] for an highly readable, but informal introduction.}.

Denoting $\log(\lambda_{t})$ as $\zeta_{t}$ and rearranging, we can see that the conditional mean of $Z_{t}$ is given by

\begin{equation}
  \zeta_{t}=\log(\lambda_{t})=\big[ \phi^{-1}(B)\psi(B)(1-B)^{-d}-1\big] e_{t}
  (\#eq:EFARIMApdqConditionalMean)
\end{equation}

where $E(\zeta_{t})=0$

The autocorrelations of $Z_{t}$ - which follow a scaling law - exhibit a hyperbolic decay (See Figure \@ref(fig:hyperbolicACF)), the speed of which depends upon the parameter $d$

\begin{equation}
  \rho(k)\sim c_{\rho}^{Z}|k|^{2d-1}
  (\#eq:acfFARIMA)
\end{equation}

where $c_{\rho}^{Z}>0$ is a constant.

```{r hyperbolicACF,echo=FALSE,auto_pdf = FALSE,out.width = '75%',fig.cap="Long-Memory - Hyperbolic ACF",fig.align = 'center'}
# define hyperbolic ACF function
hyperbolicACF <- function (c,k,d){
  rho<-c*abs(k)^(2*d-1)
}

# compute ACF for different d
acf15<-hyperbolicACF(1,1:100,0.15)
acf20<-hyperbolicACF(1,1:100,0.2)
acf30<-hyperbolicACF(1,1:100,0.3)
acf40<-hyperbolicACF(1,1:100,0.4)
acf45<-hyperbolicACF(1,1:100,0.45)

# create data frame
hyperbolic_acf_df<-data.frame(t(rbind(seq(1,100),acf15,
  acf20,acf30,acf40,acf45)))
colnames(hyperbolic_acf_df)<-c('lag','d=0.15','d=0.20',
  'd=0.30','d=0.4','d=0.45')
# reshape data frame for ploting via ggplot
hyperbolic_acf_df_m<-melt(hyperbolic_acf_df,id='lag')

# crate plot
titleName='ACF By Fractional Difference Parameter (d)'
xLabel<-'Lag'
yLabel<-'ACF'
g_hyperbolicACF<-ggplot(hyperbolic_acf_df_m)+
  geom_line(aes(x=lag,y=value,color=variable))+
  ggtitle(titleName) + xlab(xLabel) + ylab(yLabel)+
  scale_colour_manual(values=c("red","black","blue",
    "grey","purple","navy"))

# print the graph
print(g_hyperbolicACF)

```

For non-integer values of $d$, the autocorrelation function (ACF) decays hyperbolically to zero according to \@ref(eq:acfFARIMA) (See Figure \@ref(fig:hyperbolicACF)).

The general class of models defined by \@ref(eq:marketModelLogRangeProcess) and \@ref(eq:EFARIMApdq) are referred to as *exponential FARIMA (EFARIMA)* models in the literature [@Beran2015-kz]. Where $e_{t}$ are normally distributed, the model is referred to as a *Gaussian EFARIMA* model.

Setting $p=0$ and $q=0$, the innovations, $e=\log(\eta_{t})$, simplify to

\begin{equation}
  (1-B)^{d}Z_{t}=e_{t}
  (\#eq:EFARIMAd)
\end{equation}

This simpler specification is particularly useful for sensitivity analysis. Equation \@ref(eq:marketModelLogRangeProcess) is denoted EFARIMA(0,$d$,0).

Our market model has two sources of uncertainty, namely $\epsilon$ and $e$. Bursts in volatility driven by the true range process can generate price momentum that looks very similar to that observed in real markets.

## Model Calibration

For each instrument in the universe under study, we fit an EFARIMA(0,$d$,0)  model with log-normal errors. We then use the cross-section of parameters to define the starting range of parameters for use in our sensitivity analysis.

Given the definition of our market model (defined above), we observe two processes - $P_{t}$ and $R_{t}$. 

We assume that $R_{t}$ ($t=1,2,\ldots,T)$ is generated by an EFARIMA process with an unknown parameter vector

\begin{equation}
  \theta_{R}=\big( v, \sigma_{e}^{2},d,\phi_{1},\ldots,\phi_{p},\psi_{1},\ldots,\psi_{q}\big)^{T}
  (\#eq:EFARIMApdqParameters)
\end{equation}

For the EFARIMA(0,d,0) model, this parameter set reduces to

\begin{equation}
  \theta_{R}=\big( v, \sigma_{e}^{2},d\big)^{T}
  (\#eq:EFARIMAdParameters)
\end{equation}

Given that - by assumption - $Z_{t}=\log{R_{t}}-\log{v}$ is a centered Gaussian FARIMA process, maximum likelihood estimation (MLE) can be used to estimate the parameters (See [@Mills1999-bo],[@Fox1986-kk],[@Giraitis1990-pi],[@Beran1995-ug], and [@Haslett1989-wm]). This allows us to use standard, widely-available, estimation software to calibrate the model ([@McLeod2007-xr] and [@R-arfima]).

We assume that the price process is a function the volatility, which is in turn a function of $R_{t}$.

We employ the ARFIMA R package [@R-arfima] to estimate the parameters of true range for each instrument in the universe under study (See Tables \@ref(tab:marketModelParametersA), \@ref(tab:marketModelParametersB), \@ref(tab:marketModelParametersC) and ,\@ref(tab:marketModelParametersD)).

```{r,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE}
# read table of calibrated parameters by instrument
fileNameLrdLog<-'C:/Users/Derek/Documents/GitHub/IS609/final_project/coefficientsByInstrumentLog.rds'
fileLrdLog<-fileNameLrdLog
# write
coefficientsByInstrument<-readRDS(fileLrdLog)

coefficientsByInstrument[,1]<-gsub("&", "", coefficientsByInstrument[,1])
coefficientsByInstrument[,1]<-gsub("/", "", coefficientsByInstrument[,1])
coefficientsByInstrument[,1]<-gsub("#", "", coefficientsByInstrument[,1])

marketModelParamters<-data.frame(instrumentName=coefficientsByInstrument[,1],
  d=as.double(coefficientsByInstrument[,5]),
  logV=as.double(coefficientsByInstrument[,6]),
  varE=as.double(coefficientsByInstrument[,7]),
  pValueD=as.double(coefficientsByInstrument[,8]),
  pValueVar=as.double(coefficientsByInstrument[,9]),
  annualDrift=as.double(coefficientsByInstrument[,10]))

indexA<-1:29
indexB<-30:67
indexC<-68:95
indexD<-96:115

A<-marketModelParamters[indexA,]
B<-marketModelParamters[indexB,]
C<-marketModelParamters[indexC,]
D<-marketModelParamters[indexD,]

columnNames<-c('Instrument Name','d','log(V)','var(e)',
  'd p-Value','var(e) p-value','mu')

```

For the vast majority of the instruments in the universe under study, the estimated $d$ parameter is between 0.15 and 0.35.

```{r distributionDAndLogV,echo=FALSE,auto_pdf = FALSE,out.width = '50%'}
#fig.cap="Autocorrelation Function"
# Figure \@ref(fig:distributionDAndLogV)
imageFileName1<-'C:/Users/Derek/Documents/GitHub/IS609/final_project/dDistribution.png'
knitr::include_graphics(imageFileName1,dpi = NA)
imageFileName2<-'C:/Users/Derek/Documents/GitHub/IS609/final_project/logMeanTrDistribution.png'
knitr::include_graphics(imageFileName2,dpi = NA)
```

```{r marketModelParametersA,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE}
knitr::kable(A, booktabs = TRUE,
  caption = 'Global Futures - Instrument Details',
  col.names=columnNames,row.names =indexA,digits=4)

```

```{r marketModelParametersB,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE}
knitr::kable(B, booktabs = TRUE,
  caption = 'Global Futures - Instrument Details',
  col.names=columnNames,row.names =indexB,digits=4)

```

```{r marketModelParametersC,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE}
knitr::kable(C, booktabs = TRUE,
  caption = 'Global Futures - Instrument Details',
  col.names=columnNames,row.names =indexC,digits=4)

```

```{r marketModelParametersD,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE}
knitr::kable(D, booktabs = TRUE,
  caption = 'Global Futures - Instrument Details',
  col.names=columnNames,row.names =indexD,digits=4)
```

As is evident from the calibration tables, all parameters are highly significant.



```{r modelFit,echo=FALSE,auto_pdf = FALSE,out.width = '75%',fig.cap="Calibrated EFARIMA(0,1,01) - ACF",fig.align = 'center',warning=FALSE,message=FALSE,error=FALSE}
library(arfima)
library(Rcpp)

#-------------------------------------------------------------------------
# Multiple plot function (Source: Cookbook for R)
#-------------------------------------------------------------------------
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot
# objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }

  if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout),
                                               ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this
      # subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

#-------------------------------------------------------------------------
# compute ACF for each path, return ACF by path, percentile bounds, and
# mean
#-------------------------------------------------------------------------
acfPaths <- function(e,maxLag,alpha){

  dimension <- dim(e)
  nRows<-dimension[1]
  nPaths <- dimension[2]

  eAcfC<-matrix(0,nrow=maxLag,ncol=nPaths)
  eAcfLag<-matrix(0,nrow=maxLag,ncol=nPaths)

  for (pathIndex in 1:nPaths){
    # filter out NAs
    nonNaIndex<-!is.na(e[,pathIndex]) & e[,pathIndex]!=0
    eNoNA<-e[nonNaIndex,pathIndex]
    # autocorrelation
    eAcfData<-acf(eNoNA,lag.max=maxLag,plot=FALSE)
    eAcfC[,pathIndex]<-eAcfData$acf[2:(maxLag+1)]
    eAcfLag[,pathIndex]<-eAcfData$lag[2:(maxLag+1)]
  }

  lowerPercentile<-alpha/2
  upperPercentile<-1-alpha/2
  ePercentileAcf<-apply(eAcfC,1, quantile, probs=c(lowerPercentile,
    0.5,upperPercentile), na.rm=TRUE)
  eMeanAcf<-apply(eAcfC,1, mean, na.rm=TRUE)

  output<-list(percentileAcf=ePercentileAcf,meanAcf=eMeanAcf,
               acfPaths=eAcfC)

  return (output)
}

#-------------------------------------------------------------------------
# plot median with confidence bounds
#-------------------------------------------------------------------------
plotSecenarioPerformanceWithCI<- function (marketModelParameterScenarios,
  table_figure,titleName,xLabel,yLabel){

  figure_df <- data.frame(marketModelParameterScenarios=marketModelParameterScenarios,
    Lower=table_figure[,1],Median=table_figure[,2],Upper=table_figure[,3])

  limits <- aes(ymax = Upper, ymin=Lower)

  p1 <- ggplot(figure_df, aes(marketModelParameterScenarios)) +
    geom_line(aes(y=Median), colour="blue") +
    scale_color_grey() +
    geom_ribbon(limits, alpha=0.2) +
    ggtitle(titleName) + xlab(xLabel) + ylab(yLabel)

  return (p1)

}

#-------------------------------------------------------------------------
# convert true range to sigma (based on Brunetti & Lildholdt (2002))
#-------------------------------------------------------------------------
range2Sigma <- function (tr){
  # Brunetti & Lildholdt (2002) provides the relationship
  # between volatility and range
  sigma_tr<-tr*sqrt(pi/8)
  return (sigma_tr)
}

#-------------------------------------------------------------------------
# simulate N true range paths based on EFARIMA model
#-------------------------------------------------------------------------
simulateTrueRangeNPaths_LRD<-function(nRows,nPaths,parameterListLRD,
                                      xSigma2,xMean){

  xSigma<-sqrt(xSigma2)

  tr<-matrix(0,nRows,nPaths);

  for (pathIndex in 1:nPaths){
    #
    e<-arfima.sim(nRows,parameterListLRD)
    #
    tr[,pathIndex]<-exp(e*xSigma+xMean)

  }
  #
  return (tr)
}

#-------------------------------------------------------------------------
# simulate nPaths price and true range paths based on CARR model
#-------------------------------------------------------------------------
singleMarketModel_LRD<-function(S0,mu,T,nRows,nPaths,parameterListLRD,
                                xSigma2,xMean){
  # simulate the true range based on EFARIMA model
  tr<-simulateTrueRangeNPaths_LRD((nRows-1),nPaths,parameterListLRD,
                                  xSigma2,xMean)
  # convert the true range to sigma using relationship in
  sigma_tr<-range2Sigma(tr)
  # simulate the return
  e <- matrix(rnorm((nRows-1)*nPaths,mean = 0, sd = 1),(nRows-1),nPaths)
  # determine delta time increment
  dt <- T/(nRows-1)
  # determine drift per delta time increment
  nudt_t <- (mu*dt)
  #nudt <- (mu-0.5*sigma_tr^2)*dt
  # add drift and multiply by true range (%)
  # (we multiply the true range percent by 100 during model estimation
  # so we have to divide by 100)
  increments <- nudt_t + ((sigma_tr)*e)
  # combine initial price (S0) and increments
  x <- rbind(matrix(log(S0),1,nPaths),increments)
  # convert returns to prices
  pricePaths=exp(apply(x,2,cumsum))
  # return price and true range paths
  return (list(pricePaths=pricePaths,tr=tr,sigma_tr=sigma_tr))
}


# ACF parameters
maxLag<-250
alpha<-0.05

fileNameLogE<-'C:/Users/Derek/Documents/GitHub/IS609/final_project/logE.rds'

LogE<-readRDS(fileNameLogE)

fileNameLogF<-'C:/Users/Derek/Documents/GitHub/IS609/final_project/logF.rds'

LogF<-readRDS(fileNameLogF)

#
acfLogE<-acfPaths(LogE,maxLag,alpha)
#
acfLogF<-acfPaths(LogF,maxLag,alpha)

xLabel<-'Lag (k)'
yLabel<-'ACF'
titleName<-'ACF (Calibrated) \n Residuals'
marketModelParameterScenarios <- (2:(maxLag+1))
table_figure<-round(t(acfLogE$percentileAcf),4)

logE_ACF<-plotSecenarioPerformanceWithCI(marketModelParameterScenarios,
  table_figure,titleName,xLabel,yLabel)
#print(logE_ACF)
ggsave('C:/Users/Derek/Documents/GitHub/IS609/final_project/LogE_ACF.png',
  plot=logE_ACF)

xLabel<-'Lag (k)'
yLabel<-'ACF'
titleName<-'ACF (Calibrated) \n Conditional Mean True Range'
marketModelParameterScenarios <- (2:(maxLag+1))
table_figure<-round(t(acfLogF$percentileAcf),4)

logF_ACF<-plotSecenarioPerformanceWithCI(marketModelParameterScenarios,
  table_figure,titleName,xLabel,yLabel)
#print(LogF_ACF)
ggsave('C:/Users/Derek/Documents/GitHub/IS609/final_project/LogF_ACF.png',
  plot=logF_ACF)

multiplot(logE_ACF,logF_ACF,cols=2)
ggsave('C:/Users/Derek/Documents/GitHub/IS609/final_project/Log_E_F_ACF.png')

```

The EFARIMA(0,d,0) model for true range provides a framework for forecasting the conditional mean true range. These predictions could replace the EMA smoothed true range in the simple trend-following system (detailed in the next Chapter), potentially significantly improving the effectiveness of the the position-sizing and trailing stop loss components of the trading system.  

It is evident from Figure \@ref(fig:modelFit) that model residuals retain some short-term memory, suggesting that a EFARIMA(p,d,q) model could provide a better fit. To reduce the dimension of our sensitivity analysis, we use the simpler model (recognizing that it captures the broader long memory but could likely be improved with a higher order model).

Using the market model, we simulate a single price and true range path for each instrument and plot the results to provide an intuitive means of checking the realism of the model (Figure \@ref(fig:marketModelCalibratedPaths)). The simulated paths appear similar to the actual paths (shown in Chapter \@ref(intro))

```{r,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE,eval=FALSE}
# define parameters
randomSeed<-1234567

# market model parameters
S0<-1
T<-5
nRows<-1250
nPaths<-1

# iterate over the parameters and simulate paths

dimension<-dim(LogE)
nInstruments<-dimension[2]

d<-as.double(coefficientsByInstrument[,5])
logV<-as.double(coefficientsByInstrument[,6])
varE<-as.double(coefficientsByInstrument[,7])
mu<-as.double(coefficientsByInstrument[,10])

marketModelPricePaths<-matrix(NA,nRows,nInstruments)
marketModelTrPaths<-matrix(NA,nRows,nInstruments)

set.seed(randomSeed)

for (instrumentIndex in 1:nInstruments){
  # create parameter list
  parameterListD=list(dfrac=d[instrumentIndex])
  
  # generate path
  marketModelResult<-singleMarketModel_LRD(S0,mu[instrumentIndex],
    T,nRows,nPaths,parameterListD,
    varE[instrumentIndex],logV[instrumentIndex])
  
  #
  marketModelPricePaths[1:nRows,instrumentIndex]<-marketModelResult$pricePaths
  #
  marketModelTrPaths[2:nRows,instrumentIndex]<-marketModelResult$tr
  
}

#-------------------------------------------------------------------------
# create the total return index paths plot
#-------------------------------------------------------------------------

# create title label for graph
titleName<-'Market Model - Simulated Price Paths (Calibrated)'
xLabel<-'Time'
yLabel<-'Total Return Index'
# create the terminal wealth relative (TWR) data frame
twr_df<-data.frame(timeIndex=seq(1:nRows),marketModelPricePaths)
# convert the 'wide' form data to 'long' form 
twrLongDf<-melt(twr_df,id="timeIndex")


p1<-ggplot(data=twrLongDf,aes(x=timeIndex,y=value,colour=variable))+
  geom_line(size = 0.25)+
  ggtitle(titleName)+
  scale_color_grey() + theme_classic()+
  theme(legend.position="none")+
  xlab(xLabel)+ylab(yLabel)

#-------------------------------------------------------------------------
# create the total return index true range paths plot
#-------------------------------------------------------------------------

# create title label for graph
titleName<-'Market Model - Simulated True Range Paths (Calibrated)'
xLabel<-'Time'
yLabel<-'True Range'
# create the terminal wealth relative (TWR) data frame
tr_df<-data.frame(timeIndex=seq(1:nRows),marketModelTrPaths)
# convert the 'wide' form data to 'long' form 
trLongDf<-melt(tr_df,id="timeIndex")

p2<-ggplot(data=trLongDf,aes(x=timeIndex,y=value,colour=variable))+
  geom_line(size = 0.25)+
  ggtitle(titleName)+
  scale_color_grey() + theme_classic()+
  theme(legend.position="none")+
  xlab(xLabel)+ylab(yLabel)

#-------------------------------------------------------------------------
# arrange the graphs together 
#-------------------------------------------------------------------------
p3<-multiplot(p1,p2,cols=1)
ggsave('C:/Users/Derek/Documents/GitHub/IS609/final_project/calibratedPaths.png',
  plot<-p3)

```

```{r marketModelCalibratedPaths,echo=FALSE,auto_pdf = FALSE,,out.width = '75%',fig.align = 'center',fig.cap="Market Model - Simulated Paths (Calibrated to Global Futures)"}
#
# Figure \@ref(fig:distributionDAndLogV)
imageFileName1<-'C:/Users/Derek/Documents/GitHub/IS609/final_project/calibratedPaths.png'
knitr::include_graphics(imageFileName1,dpi = NA)
```

